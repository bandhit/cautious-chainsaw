{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import EMNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = EMNIST(\n",
    "    root = 'data',\n",
    "    split = 'digits',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor())\n",
    "\n",
    "test_data = EMNIST(\n",
    "    root = 'data',\n",
    "    split = 'digits',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 2 ** 14\n",
    "train_dataloader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_dataloader = DataLoader(test_data, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x: np.ndarray\n",
    "y: np.ndarray\n",
    "for x, y in test_dataloader:\n",
    "    print(f'shape of x [n, c, h, w]: {x.shape} {x.dtype}')\n",
    "    print(f'shape of y: {y.shape} {y.dtype}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import LogSoftmax\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import Module\n",
    "from torch.nn import ReLU\n",
    "from torch import flatten\n",
    "\n",
    "class LigmaNetwork(Module):\n",
    "    def __init__(self):\n",
    "        super(LigmaNetwork, self).__init__()\n",
    "        \n",
    "        self.conv1 = Conv2d(in_channels = 1, out_channels = 20, kernel_size = 5, stride = 1)\n",
    "        self.relu1 = ReLU()\n",
    "        self.pool1 = MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.conv2 = Conv2d(in_channels = 20, out_channels = 50, kernel_size = 5, stride = 1)\n",
    "        self.relu2 = ReLU()\n",
    "        self.pool2 = MaxPool2d(kernel_size = 2, stride = 2)\n",
    "\n",
    "        win_size   = 28\n",
    "        win_size  -= 5 - 1\n",
    "        win_size //= 2\n",
    "        win_size  -= 5 - 1\n",
    "        win_size //= 2\n",
    "        flat_size  = win_size * win_size * self.conv2.out_channels\n",
    "\n",
    "        self.dense1 = Linear(in_features = flat_size, out_features = 500)\n",
    "        self.relu3 = ReLU()\n",
    "        self.dense2 = Linear(in_features = 500, out_features = 10)\n",
    "        \n",
    "        self.log_prob = LogSoftmax(dim = 1)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = flatten(x, 1)\n",
    "        x = self.dense1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dense2(x)\n",
    "\n",
    "        return self.log_prob(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LigmaNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import NLLLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "loss_fn = NLLLoss()\n",
    "optimizer = Adam(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from tqdm import tqdm\n",
    "\n",
    "max_epochs = 10\n",
    "n_batch = len(train_dataloader)\n",
    "\n",
    "i: int = 0\n",
    "with tqdm(total = max_epochs * n_batch) as pbar:\n",
    "    model.train()\n",
    "    for epoch in range(max_epochs):\n",
    "        x: Tensor\n",
    "        y: Tensor\n",
    "        y_pred: Tensor\n",
    "        loss: Tensor\n",
    "        for batch, (x, y) in enumerate(train_dataloader):\n",
    "            i = pbar.n + 1\n",
    "            \n",
    "            # move data to gpu\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            # compute prediction error\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "\n",
    "            # backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # update logs\n",
    "            pbar.set_postfix({'i': i, 'epoch': epoch + 1, 'batch': batch + 1, 'loss': loss.item()})\n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "predicted_digits: int = []\n",
    "actual_digits: int = []\n",
    "with torch.no_grad():\n",
    "    x: Tensor\n",
    "    y: Tensor\n",
    "    y_pred: Tensor\n",
    "    loss: Tensor\n",
    "    for batch, (x, y) in enumerate(test_dataloader):\n",
    "        # move data to device\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # make the predictions and calculate the validation loss\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        # move data to cpu \n",
    "        predicted_digits += y_pred.argmax(1).detach().cpu().tolist()\n",
    "        actual_digits += y.detach().cpu().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix(actual_digits, predicted_digits))\n",
    "display.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fpga001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
